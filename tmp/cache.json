{"ingress-nginx-controller___FailedBuildModel":{"Message":"Failed build model due to unable to resolve at least one subnet (0 match VPC and tags)","Answer":"{\"text\":\"[Error Message]Event: Warning / Count: 37 / Reason: FailedBuildModel / Message: Failed build model due to unable to resolve at least one subnet (0 match VPC and tags)\",\"attachments\":[{\"type\":\"mrkdwn\",\"text\":\"해당 오류 메시지는 \\\"Service ingress-nginx-controller\\\"에 대한 메시지이고, \\\"Failed build model due to unable to resolve at least one subnet (0 match VPC and tags)\\\"라는 내용은 Kubernetes에서가 아니라 AWS 환경에서 발생할 가능성이 높습니다. 특히 AWS의 Elastic Kubernetes Service(EKS)를 사용할 때 AWS Load Balancer Controller가 서브넷을 찾지 못해서 생기는 오류처럼 보입니다.\\n\\n일반적으로 Kubernetes의 Service 오류는 Selector와 Pod의 Label 불일치, 잘못된 포트 설정 등의 이유에서 발생할 수 있지만, 여기서 언급된 \\\"FailedBuildModel\\\"은 AWS 상의 네트워크 설정 문제로 추정됩니다.\\n\\nAWS에서 ingress-nginx를 사용하기 위한 Service 타입은 LoadBalancer이며, 이는 AWS의 ELB(Elastic Load Balancer)를 프로비저닝하여 트래픽을 쿠버네티스 Pod로 전달합니다. 해당 오류는 AWS Load Balancer Controller가 적절한 서브넷을 찾지 못하여 발생한 것으로 보입니다. 이는 일반적으로 AWS의 VPC설정, 서브넷 태깅, 또는 IAM 권한 설정 문제일 수 있습니다.\\n\\n해결 방안은 다음과 같습니다:\\n1. AWS Load Balancer Controller가 EKS 클러스터에서 사용하는 VPC와 일치하는 태그가 있는 서브넷을 찾을 수 있도록 확인해야 합니다. 이 작업은 AWS 관리 콘솔에서 수행할 수 있습니다.\\n2. 각 서브넷에 'kubernetes.io/cluster/{CLUSTER_NAME}'이라는 태그가 'shared' 또는 'owned' 값으로 설정되어 있는지 검사합니다. 여기서 `{CLUSTER_NAME}`은 EKS 클러스터의 이름으로 대체해야 합니다.\\n3. AWS Load Balancer Controller에 적절한 IAM Role이 연결되어 있고, 해당 Role에 ELB 리소스를 관리할 권한이 있는지 확인합니다.\\n4. EKS 클러스터가 여러 AZ(Availability Zone)에 걸쳐 있을 때, 각 AZ에 서브넷이 존재하는지 확인합니다. 그리고 이 서브넷들이 ELB를 생성할 때 사용될 수 있도록 적절히 태깅되어 있는지 확인합니다.\\n5. 필요에 따라서 AWS의 지원 팀에 문의하여 도움을 요청할 수도 있습니다.\\n\\n이러한 단계들을 확인하고 문제가 해결되지 않는 경우, 오류 메시지에서 추가적인 힌트를 찾거나 AWS 문서를 참고하여 더 깊이있는 문제 해결에 접근해야 합니다.\",\"color\":\"good\",\"title\":\"ChatGPT 결과\"}]}","Timestamp":"2023-12-08T15:04:39.791878+09:00","ErrorTime":"2023-12-08T15:04:39.791879+09:00","ErrorCount":37},"warning-pod___FailedCreatePodSandBox":{"Message":"Failed to create pod sandbox: rpc error: code = Unknown desc = failed to create containerd task: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: container init was OOM-killed (memory limit too low?): unknown","Answer":"{\"text\":\"[Error Message]Event: Warning / Count: 23 / Reason: FailedCreatePodSandBox / Message: Failed to create pod sandbox: rpc error: code = Unknown desc = failed to create containerd task: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: container init was OOM-killed (memory limit too low?): unknown\",\"attachments\":[{\"type\":\"mrkdwn\",\"text\":\"에러 메시지에 따르면, \\\"warning-pod\\\"라는 이름의 Pod를 생성하는 과정에서 Pod Sandbox를 만들 수 없었습니다. 그 원인은 Out Of Memory (OOM) Killer에 의해 Pod가 죽었다는 것을 알 수 있습니다. 즉, 이 Pod에 할당된 메모리가 너무 낮아서 Pod의 컨테이너를 시작할 수 없다는 뜻입니다.\\n\\n이 문제를 해결하려면 다음과 같이 Pod에 대한 메모리 요청(requests) 및 제한(limits)을 적절히 설정해야 합니다. 이 설정은 해당 Pod의 container 섹션에 온다는 가정하에 설명하겠습니다.\\n\\n1. YAML 파일에서 해당 Pod의 `spec.containers[].resources` 섹션을 찾아 수정합니다.\\n```yaml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: warning-pod\\n  labels:\\n    # ... 기타 라벨 설정 ...\\nspec:\\n  containers:\\n  - name: busybox-container\\n    image: busybox\\n    resources:\\n      requests:\\n        memory: \\\"64Mi\\\" # Pod에 필요한 최소 메모리. 예시는 \\\"64Mi\\\"로 설정했으며, 실제 요구사항에 맞게 조정해야 합니다.\\n      limits:\\n        memory: \\\"128Mi\\\" # Pod에서 사용할 수 있는 최대 메모리. 예시는 \\\"128Mi\\\"로 설정했으나, 실제 요구사항에 맞게 조정해야 합니다.\\n    # ... 기타 컨테이너 설정 ...\\n```\\n\\n2. 메모리 요청 및 제한을 조정한 후에는 수정된 YAML 파일을 적용합니다.\\n\\n```bash\\nkubectl apply -f \\u003c파일명\\u003e.yaml\\n```\\n\\n3. 수정한 YAML 파일을 적용한 후, Pod가 정상적으로 배포되고 실행되는지 확인합니다.\\n\\n```bash\\nkubectl get pods\\n```\\n\\n만약 이 방법으로도 문제가 해결되지 않는다면, 클러스터에 할당된 전체 리소스와 Pod를 배치하는 노드의 메모리 사용 여부를 확인해보아야 합니다. 노드에 충분한 여유 메모리가 없다면, Pod에 요청할 수 있는 리소스가 부족할 수 있으므로 노드를 확장하거나 리소스 사용량을 재조정해야 할 수 있습니다.\",\"color\":\"good\",\"title\":\"ChatGPT 결과\"}]}","Timestamp":"2023-12-08T15:04:39.408104+09:00","ErrorTime":"2023-12-08T15:04:39.408105+09:00","ErrorCount":23}}